\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it
% out.
\usepackage[numbers]{natbib}
\bibliographystyle{plainnat}
\usepackage{hyperref}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\graphicspath{ {./assets/} }
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{color}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}


    \title{Automatic detection of floating aquatic vegetation from remote sensing data}

    \author{\IEEEauthorblockN{Esteve Soria Fabián}
    %\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
    \textit{Universidad Internacional Menéndez Pelayo}\\
    esofabian@gmail.com}
    %\and
    %\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
    %\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
    %\textit{name of organization (of Aff.)}\\
    %City, Country \\
    %email address or ORCID}

    \maketitle

    \begin{abstract}
        The Copernicus programme~\cite{whatiscopernicus} is an Earth observation component of the European Union Space
        Programme.
        One of the missions inside the programme is Sentinel-2~\cite{sentinel-2} with 2 satellites orbiting around the
        earth.
        The two satellites, Sentinel-2A and Sentinel-2B, can provide images in 13 different bands with a resolution up
        to 10m per pixel.
        Bands range from infrared through the visible spectrum to short wave infrared.
        The programme with its policy of free access allows scientists and researchers to obtain data for several
        research fields as cropland, glacier or lake monitoring.

        In this work we focus our attention at water quality monitoring.
        During the study of several lakes in the Spanish territory, patches of an invasive species were found floating in the water.
        Finding out when, where and why these plants appear is of great interest for researchers.
        Its detection is a manual process through the use of common remote-sensing indices as NDVI~\cite{NDVIsource}
        and water segmentation.
        The problem of this approach is that its not very robust for a global scale search.

        This work proposes an automatic search system of these form of life with a little amount of labelled training data.
        This is thanks to the use of self-learning techniques applied to remote sensing.
    \end{abstract}
    \newline
    Code: \href{https://github.com/sorny92/satellite-surface-algae-detection}{github.com/sorny92/satellite-surface-algae-detection}.
    \newline

    \begin{IEEEkeywords}
        remote-sensing, computer vision, deep-learning, image retrieval, Sentinel-2, self-supervision
    \end{IEEEkeywords}


    \section{Introduction}
    Thanks to the globally connected world we live in its possible to communicate with people from distant countries or
    enjoy food from produce that is not native to our area.
    Yet, this global economy also has some disadvantages.
    Due to the global transport network and the big distances we can travel, humans have become an important vector of movement of species
    between different ecosystems~\cite{invasive_species}.
    Non-native species can become threats to biological ecosystems and disrupt all sort of environments,
    from lakes or forests to whole countries~\cite{bhlitem21490}.

    For many years researchers have been tracking and studying different invasive vegetation~\cite{huang2009applications, aguir2013, donyana1, donyana2} species.
    In this project we seek to automatically detect the location of aquatic vegetation floating in the water.
    The motivation is to provide a tool that could help the detection of this vegetation.
    But also provide a tool to be able to detect any other type of species or even locate other kind of images thanks to the
    high level information that provides the model generated in this work.

    In this work we use self-supervised techniques to train a model to generate embeddings from a patch of a tile.
    Embeddings are a numerical representation of some information, in our case, an image.
    Embeddings allow to compress the information contained in an image to a much manageable and representative list of values.

    We use BarlowTwins~\cite{barlowtwins} framework to train an embeddings generating architecture for remote-sensing.
    We chose to use BarlowTwins for its simple architecture which does not require a momentum encoder (like MoCo~\cite{he2020momentum, grill2020bootstrap}).
    Also, it does not need negative sampling as SimCLR~\cite{chen2020simple} which becomes helpful with satellite imaging as it allows to use
    all the world indiscriminately without having to create contrastive triplets.
    The simple architecture allows for a training that can happen in low budget systems and a minimal labelled amount of data.

    For the use of the system, fine-tuning a classification head becomes trivial with only hundreds of images with positive and negative
    samples of the target classes.
    Although, because the model can generate embeddings from any Sentinel-2 image it can also be used as a tool for image retrieval
    where the researcher can provide example images of what is looking for and the system will return the closest images that
    have been indexed.

    For this project, images have been sourced from the pair of satellites Sentinel-2~\cite{sentinel-2}.
    These satellites haven been operating since 2015 providing remote sensing capabilities in the range of latitudes between 56º S and 84º N\@.
    This satellite can pass above the same point every 5 days allowing researchers and companies to track specific locations
    to study how they change on time.
    This satellite has 13 different bands or wavelengths with a resolution up to 10m per pixel.
    Bands range from infrared through the visible spectrum to short wave infrared.
    The indexation of several bands together end up being really useful for some task as, for example, monitoring vegetation~\cite{TUCKER1979127}.
    Another use is the tracking of water levels of different lakes or the effect of flooding and natural catastrophes.

    Remote sensing has its own set of tools, approaches and problems.
    Some research is approached as a traditional computer vision problem were the researchers will
    generate their own heuristics to be able to track the metric they are interested in.
    An example of this is the NDVI~\cite{NDVIsource} metric which uses the bands from near infrared and red to
    measure the leaf water content and chlorophyll content~\cite{TUCKER1979127}.

    One of the problems of the heuristic approach is its own simplicity, it is excellent at measuring
    vegetation, but it also comes with its own problems.
    NDVI for example, is quite sensitive to the amount of atmosphere there is between the capture system and the target and
    the behaviour compared between different capture system is not constant~\cite{Huang2021}.

    Machine learning techniques can be useful to deal with the problems of heuristic based methods as they can fit the best model
    based on the data provided of the problem.

    Thanks to the increasing amount of satellites and aerial programs, there are many different providers with remote sensing capabilities.
    In section~\ref{sec:dataset} we will delve deeper into some of the data available today but nevertheless here some details of the Sentinel-2 platform
    which is used in this project:
    \begin{itemize}
        \item 4 bands at 10 meters resolution per pixel.
        \item 6 bands at 20 meters resolution per pixel.
        \item 3 bands at 60 meters resolution per pixel.
        \item Range of latitudes between 56º S and 84º N.
        \item Visit the same location with the same angle every 10 days or 5 days using two satellites.
        \item Tiles of 290 km in size.
        \item 10980x10980 pixels of resolution.
    \end{itemize}
    The amount of data available is quite big, the problem is gathering insights of it as there's not as much labelled data
    available.
    For this project a small dataset had to be gathered, so we could benchmark how effective this framework is to detect the
    floating vegetation.

    In this project we study an improved pipeline for ease of detection of this vegetation in lakes but also provide a tool
    to retrieve similar images in a tile that are a region of our interest.
    Currently, there are some lakes that are being tracked in a manual way where the researchers would apply several filters to detect them.
    This research makes use of data from the Cedillo dam in Spain spanning from the town of Cedillo to Alcántara.
    In figure~\ref{fig:satellite-image-airbus} an example of the vegetation mat can be seen.
    Other researchers have worked in similar projects in Doñana National park (Spain)~\cite{donyana1, donyana2} or California state (USA)~\cite{rs14133013}.
    These approaches can't scale to more lakes without more people looking for them as the tools currently used are targeted
    for specific use cases and heuristics need to be developed for each individual case.
    So doing a search at a global scale can not even be considered.

    \begin{figure}[h]
        \centering
        \includegraphics[width=9cm]{figure_algae_airbus}
        \caption{Aerial image of an aquatic vegetation floating mat in the Cedillo lake (Spanish-Portuguese border). It can easily be identified as it's distinctive
        intense green colour in comparison of the water. Images from Airbus, CNES/Airbus, IGP/ DGRF 2023}
        \label{fig:satellite-image-airbus}
    \end{figure}


    \section{Related work}
    A big concern is the damage floating vegetation create for the biodiversity of aquatic areas and how this mats can cover the sunlight for species that live underwater.
    There are authors that have worked in the detection and tracking of these mats~\cite{donyana1, donyana2,rs14133013, srilanka_veg, 10.3389/fmars.2022.1004012} in different areas of the world.

    There are several approaches that can be followed:
    \subsection*{Heuristic based methods}

    Authors like~\citet{srilanka_veg, 10.3389/fmars.2022.1004012} use pixel level classification models with manually annotated data from satellite image but also UAVs.
    Depending on the authors, there are different classes they use as target for the classification system.
    For example \citet{rs14133013} uses 8 classes: 4 different surface level species, one for submerged vegetation, one for non-photosynthetic vegetation, soil and water.
    To label the data the authors generate polygons of areas in the water based on GPS data from in-situ measurements and use GIS technologies to match them with the images from the satellite.

    \citet{10.3389/fmars.2022.1004012} also follow a similar approach taking measurements of the reflectance of the different classes in-situ to then match this values to the aerial images.
    Then they use a SVM based classification technique to train a model due to the good performance they offer with low amounts of data~\cite{Cortes1995}.

    Other works as \citet{rs12244021} achieve a good performance for a country scale detection system.
    In their research they make use of a multistage system where: First, water is detected using the index MNDWI, then a second stage to detect vegetation in the water using NDVI index, then a classifier to
    identify different species of vegetation in the water.
    This is a complete end-to-end approach that accomplish what we are looking for in this project but there are number of parameters and heuristics that need to be adjusted to make the system to work.
    As another disadvantage is that it focuses in one single specie, so the parameters and thresholds of the multistage system will have to be adapted to each new problem or situation.
    In our work we focus in the ability of the system to adapt to any image and be able to retrieve similar ones only based on a small subset of images of a region of interest.


    \subsection*{Data driven methods}
    Since the appearance of AlexNet~\cite{NIPS2012_c399862d}, deep neural networks have become state of the art systems for visual recognition.
    The problem of deep learning models is the amount of data that is required to train them effectively.
    This is a big problem for the detection of this plants as many of the research conducted in the past required having researchers in-situ to capture the data that then
    would be used to create a system for tracking and detection.

    There are also, several challenges of remote sensing image scene classification\cite{9127795}:
    \begin{itemize}
        \item Big intraclass diversity;
        \item High interclass similarity (also known as low between-class separability);
        \item Large variance of object/scene scales;
        \item Coexistence of multiple ground objects
    \end{itemize}

    \subsubsection{Supervised}

    \textcolor{red}{More data driven stuff\cite{9127795, Mendieta2023GFMBG, jean2019tile2vec, akiva2020h2onet}}
    \textcolor{red}{More segmentation stuff \cite{Li_2022, inproceedings, 9460820, kirillov2023segment, akiva2020h2onet, 10135093}}
    Image segmentation has been traditionally expensive to label due to the nature of the label.
    This problem can be solved in different ways.

    \subsubsection{Self-supervised}

    There are several approaches for self-learning.
    Generative, predictive and contrastive.
    In the past years the generative approach used to be the most common one with the use of GANs~\cite{goodfellow2014generative, radford2016unsupervised}.
    Nowadays, the interest has shifted for contrastive methods as they are showing strong results in comparison with supervised methods.
    \textcolor{red}{Get a bit deeper in self supervised: \cite{wang2022selfsupervised, DINO, barlowtwins, Li_2022, grill2020bootstrap, Jung2021SelfsupervisedLW, li2022efficient, caron2021unsupervised, inproceedings, 9460820}}

    \subsection*{Decrease of data labelling time}

    The gathering of data required to be on-site can be reduced with the use of labelling tools to assist the researchers.
    For example, some researchers used in-situ measurements to then draw polygons that delimited the pixels that covered the area of interest.
    Nowadays with the use of tools as Segment Anything (SAM)~\cite{kirillov2023segment} which allows segmenting any type of image based on priors, the labelling time would be much shorter.
    These priors could be points or bounding boxes provided as input instead of whole polygons that take much longer to draw.
    In our case, as the dataset contains few images with tenths of bounding boxes, SAM could be used to find the perimeter
    of the vegetation mats and be used as inputs to train a segmentation model.
    We have images of the whole earth if we can have enough images with ground truths as in figure~\ref{fig:tile-segmented}.
    We could train a system to segment this bodies in each tile so as the satellite is moving around the earth, an automated system could run when these tiles are being generated in real-time.

    \begin{figure}[h]
        \centering
        \includegraphics[width=9cm]{segmented_tile}
        \caption{\textcolor{red}{IMAGE NEEDS TO BE CHANGED TO ONE OF OUR PROJECT:
        On the left a crop of a tile from Sentinel-2. On the right a segmented image of the crop showing the
        location of the vegetation mat.}}
        \label{fig:tile-segmented}
    \end{figure}


    \section{Datasets}\label{sec:dataset}
    For remote sensing tasks there are several sources of data.
    These are mostly aerial or from satellites.
    Depending on the resolution and spectral requirements different datasets can be used.
    For example for semantic segmentation SEN12MS~\cite{SEN12MS_dataset} is available with multi-spectral images
    in SAR and the 13 bands of Sentinel and labels for land cover and land use.
    Other semantic segmentation datasets as Postdam~\cite{postdam_dataset} provide high resolution images, 5cm per pixel of
    city areas.

    The biggest datasets available for classification task are BigEarthNet~\cite{bigearthnet}, EuroSAT~\cite{helber2019eurosat},
    PatternNet~\cite{patternet} or Million-AID~\cite{millionaid}.

    Some of them as BigEarthNet or EuroSAT include multispectral data (MSI) as they come from Sentinel-2, but others like PatterNet or Million-AID are restricted to RGB data.
    Due to the higher information that multispectral datasets provide for some research it is worth the use of MSI rather than RGB\@.

    In our work we choose to use EuroSAT for pretraining because it provides multispectral information.
    We believe it can be more helpful for the system because previous works used NDVI which uses spectral bands, as nearinfrared (NIR), that are not available for RGB images.
    We could have used BigEarthNet but due to the limitations in computation it's not feasible to train in a reasonable time over the whole dataset.

    As we have said earlier, EuroSAT provides a dataset with images from Sentinel-2 which is the same provider as the data
    we have manually labelled for the classification of the floating vegetation.

    To test the system capabilities to detect floating vegetation mats a small dataset has been gathered with 140 labels.
    The labels are rectangles where the area can eventually have vegetation floating in water.
    The labelled data consists in a table with the region of interest (ROI) being defined by the corner coordinates in WKT format, the label and the date
    of the image where it was located.
    An example of two images can be seen at figure~\ref{fig:vegetation_example}.
    This dataset has been labelled manually for this work.
    With that information the image can be extracted from the Sentinel-2 Open Access Hub.
    Sentinel-2 data can be loaded with the use of EOReader~\cite{eoreader_paper} and Python which makes an easy integration with the deep learning ecosystem.

    This dataset has three labels.
    The label `no vegetation' indicate images of the same coordinates as the ones marked as `vegetation' but in a different date, so there is only water in the ROI\@.
    The figure~\ref{fig:vegetation_example} shows how do they look like.

    The label `unknown' shows random patches of the same size as the labelled images from the same tile.
    The assumption is similar to the one done in other works with contrastive learning as simCLR~\cite{chen2020simple, jean2019tile2vec}.
    Data points that are far away from the anchor image are probably not the same as they are not close to it.
    Then these points are labelled with 0.1 probability to be aquatic vegetation, so we can consider it as a weak label in the dataset.


    \begin{figure}[h]
        \centering
        \subfloat{{\includegraphics[width=4cm]{figure_no_algae} }}%
        \qquad
        \subfloat{{\includegraphics[width=4cm]{figure_with_algae} }}%
        \caption{On the left a 64x64 crop of an image without vegetation. On the right a 64x64 crop of an image with vegetation.
        In red, the rectangle with the coordinates where the label has been assigned.}
        \label{fig:vegetation_example}
    \end{figure}


    \section{Approach}
    In this work we use a self-supervised learning (SSL) architecture as they have shown to generate strong baseline models.
    Following a regime of SSL we can generate a model that is able to output high quality embeddings which are not
    as good as supervised methods but allow to use huge amounts of data before fine-tuning in the domain specific to our interest.

    In this paper we separate the work in two steps: model pretraining and the classification head training.

    For the pretrained model we will use a Barlow Twins~\cite{barlowtwins} approach as it is a simple but powerful system for
    SSL.

    \subsection{Model pretraining}
    Barlow Twins differentiates itself from other methods as it is more resistant to a unique embedding collapsed solution.
    Also, it only uses one neural network reducing the usage of memory during training.

    We mostly follow the same setup as the original publication~\cite{barlowtwins} with some differences to adapt it to out use case.
    The backbone architecture used is a ResNet50~\cite{he2015deep} shown in figure~\ref{fig:resnet50} with 2048 outputs then connected to a projector network as in the original work.

    \begin{figure}
        \centering
        \includegraphics[width=9cm]{Resnet50}
        \caption{Architecture of Resnet50}
        \label{fig:resnet50}
    \end{figure}

    \subsubsection{Data augmentation}
    In the original work they use a series of image augmentations that we can't apply in our system.
    Some of the image augmentations as solarization, color jitter and conversion to grayscale do not make sense in multi-spectral images.

    Solarization is normally implemented as a clipping value in the luminance channel, it is not possible to convert multi-spectral data to
    a colorspace that separates luminance as this is based on human perception.
    So we decide to not use solarization in the image augmentation pipeline.

    Color jitter is also implemented as a conversion to LAB where the channels A and B are randomly increased or decreased from their mean value.
    In our case we decide to do the same for every band of the image as it is assumed to be the closer behaviour.

    The conversion to grayscale does not make sense either, so it is not used too.

    Finally, as we are using EuroSAT for pretraining we are limited on the size of the images as they have 64x64, we do not want to change the scale of the images.
    For this we choose to add affine transforms to the images to then crop them back to 64x64.
    The goal of this augmentation is changing the shape of the objects of the image to create more variety and avoid overfitting.

    \subsubsection{Optimization}
    We follow the same protocol as in the original work~\cite{barlowtwins} which follow the same as BYOL~\cite{grill2020bootstrap}.
    Use of LARS optimizer and training for 1000 epochs.
    We keep all hyperparameters the same other than batch size, where we use 256 instead of 2048 as that is the maximum we could fit in memory.
    Using 256 instead of 2048 is going to potentially cause a degradation in performance as~\citet{grill2020bootstrap, chen2020simple, barlowtwins}
    show, the bigger the batch size the better performance there is during training.

    \begin{figure}[h]
        \centering
        \includegraphics[width=9cm]{train_loss}
        \caption{Training loss graph.}
        \label{fig:training_loss_graph}
    \end{figure}

    \subsection{Classification model}
    Once the backbone was trained we freeze the weights of all the Resnet layers and append to the embeddings output node a series of fully connected layers.
    It is common in the literature for SSL to append a linear layer with as many outputs as the classification problem.
    In our case we are going to test two classification problems.
    First classification on EuroSAT test set for the 10 classes available.
    Then for the presence of aquatic vegetation mats in the water.

    \subsubsection{Data augmentation}
    For fine-tuning we use the same data augmentation protocol than in the pretraining.

    \subsubsection{Optimization}
    For EuroSAT classification a batch size of 256 is used and a learning rate of 0.1 with the Adam optimizer for 50 epochs of trainning.
    Then CosineAnnealingLR~\cite{loshchilov2017sgdr} is used during training.

    For fine-tuning the aquatic vegetation mat classifier a batch size of 32 is used as they whole dataset is only ~140 images.
    Binary cross entropy is used as loss function and the adam optimizer with learning rate of $1\cdot10^{-3}$ is used.
    The model is then trained for 20 epochs or until the loss stabilizes.


    \begin{figure}[h]
        \centering
        \includegraphics[width=9cm]{tsne_eurosat}
        \caption{t-SNE visualization of EuroSAT test set.}
        \label{fig:tsne_eurosat}
    \end{figure}


    \section{Main results}

    \subsection{Eurosat embeddings visualization}

    In figure~\ref{fig:training_loss_graph} the training graph can be seen where there are no big steps in the loss which means the training was stable and converging.
    A sudden change on the loss function could have indicated a collapse of the embeddings but this does not seem to happen.

    To check that the model is generating embeddings which are able to represent the classes of the EuroSAT data we use t-SNE~\cite{JMLR:v9:vandermaaten08a}.
    This technique allows for easy embeddings visualization of high dimensional data as it clusters together data with similar values while it moves away
    values that are further away.
    In figure~\ref{fig:tsne_eurosat} we can visualize the representation.
    We can see a clear cluster for the SeaLake class.
    Also, we can observe how HerbaceousVegetation, PermanentCrop, AnnualCrop, Forest and Pasture are found more or less mixing with each other.

    Residential and Industrial are mostly found together which makes sense as they have a similar appearance from satellite images.

    \subsection{Eurosat fine-tuning}

    As it can be seen in the table~\ref{table:eurosat_results}, our work does not improve over the supervised use case.
    But this is not the goal as for the dataset that we use later for the floating vegetation detection we do not have enough
    data to train a whole neural network.
    The results show that the embeddings generated from the model are good enough to almost achieve supervised level results,
    without having access to labelled data.


    \begin{table}[h!]
        \centering
        \begin{tabular}{ |p{3cm}||p{2cm}|p{2cm}|}
            \hline
            Model                                    & Architecture & Accuracy Top-1 \\
            \hline
            \hline
            Supervised                               & Resnet50     & 98.5\%         \\
            SSL4EO-S12(MoCo)\cite{wang2023ssl4eos12} & Resnet50     & 98.0\%         \\
            SSL4EO-S12(DINO)\cite{wang2023ssl4eos12} & Resnet50     & 97.2\%         \\
            SSL+Linear (Ours)                        & Resnet50     & 96.5\%         \\
            \hline
        \end{tabular}
        \caption{Results for eurosat classification model}
        \label{table:eurosat_results}
    \end{table}

    \subsection{Custom vegetation dataset embeddings visualization}
    In figure~\ref{fig:tsne_vegetation} we can visualize the representation of the two classes we have labelled plus a set of images
    with unknown label.

    \begin{figure}[h]
        \centering
        \includegraphics[width=9cm]{tsne_vegetation}
        \caption{t-SNE visualization of the custom dataset.}
        \label{fig:tsne_vegetation}
    \end{figure}

    In a similar fashion as in figure~\ref{fig:tsne_eurosat}, we can see a separation between the `vegetation' and `no vegetation' labels
    indicating the model trained on EuroSAT dataset is able to produce significant differences in the embeddings for different classes.
    So there's a boundary that can be created between the two.
    In addition, it can be seen the unknown data which is from the same tile is distributed in the representation space not being a single cluster
    showing again the model has not collapsed.

    \subsection{Custom vegetation dataset fine-tuning}
    After training the model in the same way as the EuroSAT classifier with our custom dataset, we obtain an accuracy of 79\%.
    This value is hard to compare to other works as the datasets are not the same neither the same area, so the data is only comparable as they look for the same
    class but in different environments.
    The values provided in table~\ref{table:vegetation_results} accounts for the same specie of plant or at least the most similar situation,
    which is the floating aquatic vegetation in a lake.
    \begin{table}[h!]
        \centering
        \begin{tabular}{ |p{2cm}||p{1.5cm}|p{2.2cm}|p{1.3cm}|}
            \hline
            Model              & Architecture & Accuracy Top-1 & F1 score \\
            \hline
            \hline
            \citet{rs12244021} & RandomForest & 98\%* 93\%**   & 87\%**   \\
            \citet{rs14133013} & Index-tuning & 79-91\%***     & -        \\
            SSL+Linear (Ours)  & Resnet50     & 79\%           & 72\%     \\
            \hline
        \end{tabular}
        \caption{
            *This score is the accuracy over the detection of vegetation. \\
            **This score is the accuracy for each class. \\
            *** This score is for Water Hyacinth and Water Primrose as they are the similar class to the one in our dataset}
        \label{table:vegetation_results}
    \end{table}

    This work also approaches the problem as a scene recognition problem, so we classify if an image contains or not aquatic vegetation.
    This is different as the other works cited in the table~\ref{table:vegetation_results} as they provide a label per pixel.

    Also, we have to take into account our model is an embedding generator, so it can be used with few data to potentially classify any Sentinel-2 image.
    Our system has been trained with approximately 140 images meanwhile ~\citet{rs12244021} used 462 images and~\citet{rs14133013} used approximately 2400 images.
    This is 3 times and 17 times fewer data, respectively.

    \begin{table}[h!]
        \centering
        \begin{tabular}{ |p{3cm}||p{1.3cm}|p{1.9cm}|p{1cm}|}
            \hline
            Model                                    & Architecture & Accuracy Top-1 & F1 score \\
            \hline
            \hline
            SSL4EO-S12(MoCo)\cite{wang2023ssl4eos12} & Resnet50     & 75\%           & 77\%     \\
            SSL4EO-S12(DINO)\cite{wang2023ssl4eos12} & Resnet50     & 79\%           & 75\%     \\
            SSL+Linear (Ours)                        & Resnet50     & 79\%           & 72\%     \\
            \hline
        \end{tabular}
        \caption{Comparison with other pretrained models from SSL4EO-S12~\cite{wang2023ssl4eos12}}
        \label{tab:vegetation_results_ssl}
    \end{table}

    We also compare our model to a couple of pretrained models from ~\citet{wang2023ssl4eos12}.
    This project trains models with worldwide Sentinel-2 data with a SSL architecture.
    We train a linear layer for the two models seen in table~\ref{tab:vegetation_results_ssl}.
    We train the DINO~\cite{DINO} model with adamW~\cite{loshchilov2019decoupled}, a learning rate of $1\cdot10^{-3}$.
    Then we train the model based on MoCo~\cite{chen2020mocov2} with adamW~\cite{loshchilov2019decoupled} too and a learning rate of $5\cdot10^{-2}$.

    As seen in table~\ref{tab:vegetation_results_ssl}, even with a smaller dataset compared to SSL4EO-S12, this scene classification problem receives a
    similar accuracy.
    The limiting factor in accuracy for the problem is the data.
    Looking into the dataset and which images are failing, we can observe that some of the images that appear as no vegetation actually have some
    vegetation

    \begin{figure}[b]
        \centering
        \includegraphics[width=9cm]{example_vegetation_retrieval}
        \caption{Examples of image retreival through similarity. The first image is the queried image and the next 9 images are the closests one in similarity.
        In this case the queried image has floating aquatic vegetation.}
        \label{fig:example_vegetation_retrieval}
    \end{figure}

    \subsection{Image retrieval}
    The embedding generator can also be used to retrieve similar images with the use of k-nearest neighbors (KNN).
    Figure~\ref{fig:example_vegetation_retrieval}, figure~\ref{fig:example_no_vegetation_retrieval} and figure~\ref{fig:example_other_retrieval} show how the system can also
    be used to search for interesting areas for research through similarity instead of index parameter tuning.



    \begin{figure}[b]
        \centering
        \includegraphics[width=9cm]{example_no_vegetation_retrieval}
        \caption{Same as figure~\ref{fig:example_vegetation_retrieval} but the first image has no aquatic vegetation.}
        \label{fig:example_no_vegetation_retrieval}
    \end{figure}


    \section{Future work}
    In this work the dataset used is quite small and only covers data from Europe.
    There are bigger datasets as BigEarthNet~\cite{bigearthnet} which cover more areas of the world then bringing more variety to the dataset.

    In that line of work, the authors of SSL4EO-S12~\cite{wang2023ssl4eos12} have created a dataset but then another problem needs to be considered
    and that is the catastrophic forgetting problem studied by ~\citet{kirkpatrick2017overcoming, de2021continual, 10135093, purushwalkam2022challenges}.

    More testing and thoughtful benchmarking needs to be done for different seasons, latitudes and weather conditions need to be done as it is not know
    how far this similarity metric can go when these variability are not considered.

    This system also uses crops of 64x64 pixels and this might be too big or too small for a generic system.
    For example in some queried images, this appears to be negative but a small part of the image contains vegetation and this is a classic problem from classification problems,
    where the target class is not big enough in the whole image.
    More data with different scales could help to find areas of interests that have different scales.

    Another interesting line of work would be the use of other architectures as most of the literature focuses in Resnet.
    A lot of work has been done with transformers and some systems like ~\cite{wang2023ssl4eos12} have testes ViT~\cite{dosovitskiy2021image} with good results in remote-sensing.


    \section{Conclusions}

    We have explored the application of self-supervised learning to remote-sensing problems.
    Specifically for the detection of floating aquatic vegetation.
    As previous works have focused in classical machine learning techniques where multi-stage heuristics need to be used or a lot of data needs
    to be gathered to be able to train a deep learning model.

    In this work we have made use of SSL to achieve a generic model which is able to generate embeddings from 64x64 images which can be used in two modes:
    As a backbone for fine-tuning with a low amount of data or as an image retrieval system.
    In our application we have achieved a 79\% accuracy which is similar to works based on CNNs for the same problem but with the use of 17 times less labelled data.

    The system used as an image retrieval system in remote-sensing is comparable as an index based search made by researchers but instead of the index selection based
    on the prior knowledge of the ROI, the researcher can just look for similar images to the ones they know.

    \section*{Acknowledgment}
    I would like to thanks to all the professors at Universidad Internacional Menéndez Pelayo for all the content they have created for this master.
    Specially thanks to Juan Miguel Soria for the idea of this project and the help and guidance about satellite imaging, remote-sensing and research guidelines.

    Also thanks to Óscar Luaces and Pablo Pérez for the corrections and guide in this work.

    Finally, thanks to all the open source community that make available all the tools that keep research active and advancing without corporate gate-keeping.




    \begin{figure}[b]
        \centering
        \includegraphics[width=9cm]{example_other_retrieval}
        \caption{Same as figure~\ref{fig:example_vegetation_retrieval} but the first image is another type different class.}
        \label{fig:example_other_retrieval}
    \end{figure}
    \bibliography{refs}


\end{document}
